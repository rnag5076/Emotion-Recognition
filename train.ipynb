{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/akash720/Facial-expression-recognition/blob/master/train.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p33rQlQOaD0e"
   },
   "source": [
    "# Importing necessary libraries and downloading files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NG-ft7y0bkCe"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-be6c502c2187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsMBPE6BXZeA"
   },
   "source": [
    "\n",
    "\n",
    "# Importing dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8XjmHBzTL3W"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'fer2013.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6e2ae67c54db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Reading the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fer2013.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Obtaining train data where usage is \"Training\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'fer2013.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'  #to suppress SettingWithCopyWarning\n",
    "\n",
    "#Reading the dataset\n",
    "dataset = pd.read_csv(\"fer2013.csv\")\n",
    "\n",
    "#Obtaining train data where usage is \"Training\"\n",
    "train = dataset[dataset[\"Usage\"] == \"Training\"]\n",
    "\n",
    "#Obtaining test data where usage is \"PublicTest\"\n",
    "test = dataset[dataset[\"Usage\"] == \"PublicTest\"]\n",
    "\n",
    "#Converting \" \" separated pixel values to list\n",
    "train['pixels'] = train['pixels'].apply(lambda image_px : np.fromstring(image_px, sep = ' '))\n",
    "test['pixels'] = test['pixels'].apply(lambda image_px : np.fromstring(image_px, sep = ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbZQVDkMYGIc"
   },
   "source": [
    "# Preparing X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xmgMNL4bpsE4",
    "outputId": "955bba23-4ac6-45d0-cfce-2d88050234d1"
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1].values\n",
    "y_train = train.iloc[:, 0].values\n",
    "X_test = test.iloc[:, 1].values\n",
    "y_test = test.iloc[:, 0].values\n",
    "\n",
    "#np.vstack stack arrays in sequence vertically (picking element row wise)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "#Reshape X_train, y_train,X_test,y_test in desired formats\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],48,48,1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],48,48,1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
    "\n",
    "print(\"shape of X_train and y_train is \" + str(X_train.shape) +\" and \" + str(y_train.shape) +\" respectively.\")\n",
    "print(\"shape of X_test and y_test is \" + str(X_test.shape) +\" and \" + str(y_test.shape) +\" respectively.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erzuNk6ycifE"
   },
   "outputs": [],
   "source": [
    "# Change to float datatype\n",
    "train_data = X_train.astype('float32')\n",
    "test_data = X_test.astype('float32')\n",
    "\n",
    "# Scale the data to lie between 0 to 1\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "\n",
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(y_train)\n",
    "test_labels_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLAloXZsayf8"
   },
   "source": [
    "# Getting number of classes and  input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ARcFF_p5cFkK",
    "outputId": "5c1c641c-8c42-4bee-b0c7-1af8db1f52dd"
   },
   "outputs": [],
   "source": [
    "# Find the unique numbers from the train labels\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    "\n",
    "# Find the shape of input images and create the variable input_shape\n",
    "nRows,nCols,nDims = X_train.shape[1:]\n",
    "input_shape = (nRows, nCols, nDims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ql830cJUbvCU"
   },
   "source": [
    "# Defining emotions name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVaXHy3XFpUM"
   },
   "outputs": [],
   "source": [
    "#Defining labels \n",
    "\n",
    "def get_label(argument):\n",
    "    labels = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Sad' , 5:'Surprise', 6:'Neutral'}\n",
    "    return(labels.get(argument, \"Invalid emotion\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYsyIgThbCfY"
   },
   "source": [
    "# Plotting an image each from train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "E24p6ptlcIDu",
    "outputId": "f0fc2b16-a29e-4ccb-a128-e41d322edbb9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[4,2])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.squeeze(X_train[2,:,:], axis = 2), cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(get_label(int(y_train[0]))))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.squeeze(X_test[1500,:,:], axis = 2), cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(get_label(int(y_test[1500]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s10xyLnfY8Fw"
   },
   "source": [
    "# Defining model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLdj9lQJPboo"
   },
   "outputs": [],
   "source": [
    "def createModel():\n",
    "    \n",
    "    #Model Initialization\n",
    "    model = Sequential() \n",
    "    \n",
    "    #Adding Input Layer\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    #Adding more layers\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "  \n",
    "    #Flattening\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Adding fully connected layer\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.6))\n",
    "    \n",
    "    #Adding Output Layer\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQfeyGnGZK-2"
   },
   "source": [
    "# Creating and training 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "colab_type": "code",
    "id": "eeqUdkV8Zs_M",
    "outputId": "db2b7059-f9d3-4fa6-b31a-14ec48e05089"
   },
   "outputs": [],
   "source": [
    "#Creating 1st model\n",
    "\n",
    "model1 = createModel()\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3528
    },
    "colab_type": "code",
    "id": "BrG5Xd-HdTUM",
    "outputId": "2a30a0f2-5bc2-475d-f281-da4b5e911eb9"
   },
   "outputs": [],
   "source": [
    "#Training our 1st model\n",
    "\n",
    "history = model1.fit(train_data, train_labels_one_hot, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                   validation_data=(test_data, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQm4EBjAZQ7c"
   },
   "source": [
    "# Evaluating 1st model and plotting curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "j8Zf-86jd7Hk",
    "outputId": "85903045-9bd6-4910-c554-c654dc8dbbb6"
   },
   "outputs": [],
   "source": [
    "#Evaluating model performance\n",
    "\n",
    "model1.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "colab_type": "code",
    "id": "mWVMn94TeCOy",
    "outputId": "2305ebf4-3969-4eeb-a9ba-35eea092dff1"
   },
   "outputs": [],
   "source": [
    "#Plotting accuracy and loss curves for 1st model\n",
    "\n",
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    " \n",
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gwK03BE6WYtY"
   },
   "source": [
    ">***As you can see that our model performs well on training set but fails to do so on test set, there must be overfitting. To remove overfitting, we can do data augmentation.***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jv8pXMQwZZoI"
   },
   "source": [
    "# Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lr0dW7KxeHbc"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        zoom_range=0.2,          # randomly zoom into images\n",
    "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,    # randomly flip images\n",
    "        vertical_flip=False)     # randomly flip images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7Iox6xhbQpg"
   },
   "source": [
    "# Creating and training 2nd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3510
    },
    "colab_type": "code",
    "id": "eTiS-2KBe5-S",
    "outputId": "fe59b7e3-8927-44e2-ec66-5fb2f1427f7b"
   },
   "outputs": [],
   "source": [
    "#Creating 2nd model and training(fitting)\n",
    "\n",
    "model2 = createModel()\n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history2 = model2.fit_generator(datagen.flow(train_data, train_labels_one_hot, batch_size=batch_size),\n",
    "                              steps_per_epoch=int(np.ceil(train_data.shape[0] / float(batch_size))),\n",
    "                              epochs=epochs,\n",
    "                              validation_data=(test_data, test_labels_one_hot),\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_gIIyLDbZws"
   },
   "source": [
    "# Evaluating 2nd model and plotting curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "y-WznumziU3k",
    "outputId": "436d2015-c65e-456d-ce8d-ef6becb728e3"
   },
   "outputs": [],
   "source": [
    "#Evaluating model performance\n",
    "\n",
    "model2.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822
    },
    "colab_type": "code",
    "id": "_WOF1I14foGu",
    "outputId": "f1ff0af2-54e2-4046-85b3-dc5f661c1a89"
   },
   "outputs": [],
   "source": [
    "#Plotting accuracy and loss curves for 2nd model\n",
    "\n",
    "# Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history2.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history2.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    " \n",
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history2.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history2.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2b6yGRcPblXE"
   },
   "source": [
    "#Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3QawkGqZLes"
   },
   "outputs": [],
   "source": [
    "#Saving our model\n",
    "\n",
    "model2.save('my_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "train.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
